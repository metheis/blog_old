<!DOCTYPE html>
<html>

<head>
    <!-- Title -->
    <title>Mark Theis Blog</title>
    <!-- Character Decording -->
    <meta charset="UTF-8">
    <!-- Browser Window Size -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Style Sheet -->
    <link rel="stylesheet" href="assets/w3-blog.css">
</head>

<!-- Body -->

<body>

    <div class="header">
        <h3><a href="https://mark.theis.site/blog/">Mark Theis's Blog</a></h3>
    </div>

    <div class="row">
        <div class="leftcolumn">
            <div class="bodycard">
                <h2>Using Clear Linux as a KVM Host</h2>
                <h5>2020 / 09 / 25</h5>
                <div style="width: 100%; height: 176px; overflow: hidden">
                    <img src="assets/images/post_2020_09_25/banner.png" style="width:100%">
                </div>
                <p>For most things that I want to accomplish in a Linux environment, I can generally either find the
                    direct solution through a quick google search, or parse solutions to analogous
                    problems and adapt them to my situation. However, I do not expect to find solutions for issues and
                    configuration challenges I arrive at with Intel’s Clear Linux.</p>
                <p>For those unfamiliar with Clear Linux, it is a Linux distribution with several optimizations for
                    Intel processors. Some people refer to it as a “benchmark distribution” because it runs extremely
                    quickly (arguably the fastest publicly available operating system in the world). It is also
                    “bleeding edge” because it is a rolling distribution: it receives kernel and package changes from
                    upstream sources within a matter of days or weeks. Larger Linux distributions such as Debian,
                    Ubuntu, Red Hat, Centos etc. release a major version of the Linux Kernel every few years and keep
                    the operating system there. Security updates and other essential features that are added to the main
                    kernel after release are then “backported.” Clear Linux does not need to do this because it keeps
                    the entire kernel up to date. I could make an entire separate post about Clear Linux and how it
                    differs from other operating systems, but for now, this explanation will suffice.</p>
                <p>Apart from being a relatively young distribution, Clear Linux does not have many users because many
                    applications do not support it, and its design makes day to day usage less
                    convenient than the likes of Ubuntu (however this has gotten better over time). This has a major
                    impact: there is significantly less community
                    support around it, so finding guides or question/answers to projects I want to implement is more
                    difficult. Therefore, in almost everything I do, I need to learn via adaptation from other OSs.
                    This is includes running virtual machines.</p>
                <p>KVM, a popular Linux method of running VMs, runs performantly because it resides within the kernel of
                    the OS. It rivals the speed of a bare metal hypervisors (such as VMware). There exists ample
                    documentation on running Clear Linux as a guest OS on KVM, however, little on using Clear Linux as
                    the host for other virtual machines. The following guide goes over how I use Clear Linux as a KVM
                    host.</p>
                <h3>Installing KVM</h3>
                <p>I assume you already have a system running Clear Linux. To find out how to install it, please see
                    <a href="https://docs.01.org/clearlinux/latest/get-started/bare-metal-install-server.html"
                        target="_blank">Intel’s guide</a>.</p>
                <p>Add the following bundles:</p>
                <pre><code><label class="unselectable"> $ </label>sudo swupd bundle-add kernel-kvm kvm-host</code></pre>
                <p>The first installs virtualization features in the kernel, and the second installs packages that that
                    allow you to manage a kvm instance.</p>
                <p>To create virtual machines, you must either login as root or add your user to the kvm user group:</p>
                <pre><code><label class="unselectable"> $ </label></code>sudo usermod -aG kvm [username]</pre>
                <p>Finally, we will utilize libvirtd to manage the virtual machines. To enable this toolkit's service:
                </p>
                <pre><code><label class="unselectable"> $ </label></code>sudo systemctl enable libvirtd</pre>
                <p>A quick <code>reboot</code> should make sure all components are enabled and ready for deployment.</p>
                <h3>Configure Networking</h3>
                <p>By default, Clear Linux directly uses a wired adapter to
                    connect to the network. However, we will need to configure a bridge to allow our virtual machines to
                    receive their own IP addresses and communicate as their own entities. Clear
                    Linux uses NetworkManager to manage interfaces. To list currently configured interfaces, run:</p>
                <pre><code><label class="unselectable"> $ </label>nmcli device status</code></pre>
                <p>Take note of the interface that you currently use for internet access. Mine was <code>eno1</code></p>
                <p>Now lets create a new bridge called <code>br0</code>:</p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con add type bridge ifname br0 con-name br0</code></pre>
                <p>We will link it to the <code>eno1</code> adapter for physical access:</p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con add type bridge-slave ifname eno1 master br0</code></pre>
                <p>(Optional) Disabled STP for the bridge (we generally don't need our bridge part of the network tree):
                </p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con modify br0 bridge.stp no</code></pre>
                <p>By default, NetworkManager assumes you will use DHCP. However, to set a static IP (replacing the
                    corresponding fields for your network):</p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con modify br0 ipv4.method manual ipv4.address "[addr/prefix_bit_length]" ipv4.gateway"[gateway]" ipv4.dns 1.1.1.1 ipv4.dns-search "example.tld"</code></pre>
                <p>Now it's time to bring down the the <code>eno1</code> interface connection:</p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con down eno1</code></pre>
                <p>And bring up the bridge:</p>
                <pre><code><label class="unselectable"> $ </label>sudo nmcli con up br0</code></pre>
                <p>Second to last, we need to prevent packets forwarded through the bridge from routing to the iptables
                    of the host. We can append the following 3 lines to a new file for our bridge in
                    <code>/etc/sysctl.d/</code> directory:</p>
                <pre><code><label class="unselectable"> $ </label>sudo nano /etc/sysctl.d/0-bridge.conf</code></pre>
                <pre><code>net.bridge.bridge-nf-call-arptables = 0<br>net.bridge.bridge-nf-call-ip6tables = 0<br>net.bridge.bridge-nf-call-iptables = 0</code></pre>
                <p>Finally, a restart of the system:</p>
                <pre><code><label class="unselectable"> $ </label>sudo reboot</code></pre>
                <p>And voilà, the bridge should work! Test out internet access or <code>ping one.one.one.one</code> to
                    verify. Also, you can
                    check the bridge with the <code>ip addr</code> command and see its IP configuration.</p>
                <h3>Define Virtual Machines</h3>
                <p>Awesome :), we have installed the prerequisite KVM packages and configured the host network, so we
                    can finally define the virtual machines!</p>
                <p>Go ahead and create a directory to store VM configuration files as well as two other (sub)
                    directories for ISOs and machine images. ISOs are the disk images that we will use to install OS’s
                    on hosts, and the machine images are the virtual drives that store the actual VM data. I keep all of
                    this on a RAID array as VMs can take up a lot of storage.</p>
                <p>Also go ahead and pick which operating system/ ISO you will use. In this example I will use CentOS 8,
                    but you can use anything else you prefer. </p>
                <pre><code><label class="unselectable"> $ </label>curl -o iso/CentOS-8.2.2004-x86_64-dvd1.iso http://linux.mirrors.es.net/centos/8.2.2004/isos/x86_64/CentOS-8.2.2004-x86_64-dvd1.iso</code></pre>
                <p>Now we will create an image for the VM (<code>200G</code> size in my case). I use the raw image
                    format as it only uses as much storage on the host as the VM uses.</p>
                <pre><code><label class="unselectable"> $ </label></code>qemu-img create -f raw images/centos_8_1.img 200G</pre>
                <p>Final piece is to define the VM and specify its parameters. We will do so using an xml file with
                    corresponding fields for each specification. Here is a corresponding <code>centos_8_1.xml</code></p>
                <pre><code>&lt;domain type='kvm'&gt;
    &lt;name&gt;centos_8_1&lt;/name&gt;
    &lt;uuid&gt;[________-____-____-____-____________]&lt;/uuid&gt;
    &lt;memory&gt;16777216&lt;/memory&gt;
    &lt;currentMy&gt;16777216&lt;/currentMemory&gt;
    &lt;vcpu&gt;8&lt;/vcpu&gt;
    &lt;cpu mode='custom'&gt;
      &lt;model&gt;Cascadelake-Server&lt;/model&gt;
      &lt;feature name="rtm" policy="disable"/&gt;
      &lt;feature name="hle" policy="disable"/&gt;
      &lt;topology sockets='1' cores='8' threads='1'/&gt;
    &lt;/cpu&gt;
    &lt;os&gt;
      &lt;type arch='x86_64' machine='pc'&gt;hvm&lt;/type&gt;
      &lt;boot dev='cdrom'/&gt;
    &lt;/os&gt;
    &lt;features&gt;
      &lt;acpi/&gt;
      &lt;apic/&gt;
      &lt;pae/&gt;
    &lt;/features&gt;
    &lt;clock offset='localtime'/&gt;
    &lt;on_poweroff&gt;preserve&lt;/on_poweroff&gt;
    &lt;on_reboot&gt;restart&lt;/on_reboot&gt;
    &lt;on_crash&gt;restart&lt;/on_crash&gt;
    &lt;devices&gt;
      &lt;disk type='file' device='disk'&gt;
        &lt;source file='/mnt/md2/vm/images/centos_8_1.img'/&gt;
        &lt;target dev='hda' bus='ide'/&gt;
      &lt;/disk&gt;
      &lt;disk type='file' device='cdrom'&gt;
        &lt;source file='/mnt/md2/vm/iso/CentOS-8.2.2004-x86_64-dvd1.iso'/&gt;
        &lt;target dev='hdb' bus='ide'/&gt;
        &lt;readonly/&gt;
      &lt;/disk&gt;
      &lt;interface type='bridge'&gt;
        &lt;source bridge='br0'/&gt;
        &lt;model type='virtio'/&gt;
        &lt;mac address="__:__:__:__:__:__"/&gt;
      &lt;/interface&gt;
      &lt;graphics type='vnc' port='3' autoport='yes' passwd='***'/&gt;
    &lt;/devices&gt;
&lt;/domain&gt;</code></pre>
                <p>I defined a VM named "centos_8_1" with 16 GB of RAM, 8 vCPUs, and attached to the ISO, disk image,
                    and
                    network bridge. Note that you will also need to create a non-conflicting MAC address as well as
                    generate a UUID. I use a python script to do so, but you can pretty much use anything as long as you
                    won't encounter conflicts. For graphics I am using VNC. This makes running VMs on a remote server
                    much
                    easier. Setting a password is good practice (and necessary for some VNC clients).</p>
                <p>With the configuration file written, you may use virsh to parse the file and create the VM:</p>
                <pre><code><label class="unselectable"> $ </label>sudo virsh define centos_8_1.xml</code></pre>
                <p>Remember that for each VM you define, it will need its own name, UUID, and MAC address.</p>
                <h3>Boot Up VM and Install OS</h3>
                <p>Let's click the digital power button!</p>
                <pre><code><label class="unselectable"> $ </label>sudo virsh start centos_8_1</code></pre>
                <p>If you want this VM to automatically start on boot, use:</p>
                <pre><code><label class="unselectable"> $ </label>sudo virsh autostart centos_8_1</code></pre>
                <p>Let's find which VNC port the VM started on:</p>
                <pre><code><label class="unselectable"> $ </label>sudo virsh vncdisplay centos_8_1</code></pre>
                <p>The output will resemble the localhost address with a port: <code>127.0.0.1:3</code>. In my case port
                    3, which corresponds to 5903 (VNC starts at port 5900 by default).</p>
                <p>If you're using a system with a desktop environment, you can login directly using a vnc client
                    pointed to <code>localhost:5903</code>. However, if running the VM on a remote server, you need to
                    forward the server port to your local machine. In a new terminal window:</p>
                <pre><code><label class="unselectable"> $ </label>ssh serveruser@[IP] -L 5903:localhost:5903</code></pre>
                <p>Now you can connect to the remote VM display using port 5903 on your local machine. Similar to
                    running the VM right on your local system, connect your VNC client to <code>localhost:5903</code>
                    with the password you set in the xml file.</p>
                <p>You should now see the OS installation GUI on your screen. Follow your OS's guided setup to install
                    on the HD image you created earlier.</p>
                <h3>Redefine VM</h3>
                <p>Now that the HD image has an operating system, we can change line 15 of the xml file to boot to the
                    <code>hd</code> instead of <code>cdrom</code>.</p>
                <pre><code></code>&lt;boot dev='hd'/&gt;</pre>
                <p>Save the file, define the machine again, and reboot it:</p>
                <pre><code><label class="unselectable"> $ </label>sudo virsh define centos_8_1.xml</code></pre>
                <pre><code><label class="unselectable"> $ </label>sudo virsh destroy centos_8_1</code></pre>
                <pre><code><label class="unselectable"> $ </label>sudo virsh start centos_8_1</code></pre>
                <h3>Finish Line</h3>
                <p>You now have a working VM running on a Clear Linux host! As mentioned earlier, if you want to
                    create more VMs, you simply need to copy the VM xml file, generate a new UUID and MAC address,
                    create a corresponding image, and install the OS as we did here. Of course, feel free to change any other
                    parameters as you see fit (for example, amount of memory or cpu allocation).</p>
                <p>Hopefully this has helped!</p>
            </div>
        </div>
        <div class="rightcolumn">
            <div class="card">
                <h2>About Me</h2>
                <img src="assets/images/mark_square_thumb.png" style="width:80%" class="center">
                <p>My name is Mark. I am a student at the University of California studying
                    towards a Bachelor of Science in Mechanical Engineering, Electrical
                    Engineering, and Computer Science.
                </p>
            </div>
            <div class="card">
                <h3>Follow Me</h3>
                <ul>
                    <li><a href="https://github.com/metheis" target="_blank">Github</a></li>
                    <li><a href="https://linkedin.com/in/mark-theis/" target="_blank">LinkedIn</a></li>
                </ul>
            </div>
        </div>
    </div>

    <div class="footer">
        <p>&copy Mark Theis <a href="" onclick="return false;">markt@berkeley.edu</a></p>
    </div>

</body>

</html>